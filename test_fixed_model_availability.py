#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿®å¤åçš„æ¨¡å‹å¯ç”¨æ€§æ£€æŸ¥
æ­£ç¡®è§£æAPIå“åº”æ ¼å¼
"""

import os
import sys
import json
import logging
import requests

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def check_model_availability_fixed():
    """
    ä¿®å¤åçš„æ¨¡å‹å¯ç”¨æ€§æ£€æŸ¥å‡½æ•°
    æ­£ç¡®è§£æä¸åŒæ ¼å¼çš„APIå“åº”
    """
    print("ğŸ” ä½¿ç”¨ä¿®å¤åçš„é€»è¾‘æ£€æŸ¥æ¨¡å‹å¯ç”¨æ€§...")
    print("=" * 60)
    
    try:
        import requests
        
        api_key = os.getenv("DASHSCOPE_API_KEY")
        if not api_key:
            return {
                "available": [],
                "unavailable": ["qwen3-omni-flash-realtime", "qwen3-vl-rerank", "qwen3-embedding"],
                "error": "æœªé…ç½®DASHSCOPE_API_KEY"
            }
        
        headers = {
            "Authorization": f"Bearer {api_key}",
            "Content-Type": "application/json"
        }
        
        # ä½¿ç”¨æ­£ç¡®çš„ç«¯ç‚¹
        base_url = "https://dashscope.aliyuncs.com"
        endpoint = f"{base_url}/compatible-mode/v1/models"
        
        try:
            response = requests.get(endpoint, headers=headers, timeout=10)
            
            if response.status_code == 200:
                models_data = response.json()
                available_models = []
                unavailable_models = []
                
                # æ£€æŸ¥APIå“åº”æ ¼å¼
                if 'data' in models_data and isinstance(models_data['data'], list):
                    # OpenAIå…¼å®¹æ¨¡å¼æ ¼å¼
                    models_list = models_data['data']
                    print(f"ğŸ“Š æ‰¾åˆ° {len(models_list)} ä¸ªæ¨¡å‹ (OpenAIå…¼å®¹æ ¼å¼)")
                    
                    target_models = [
                        "qwen3-omni-flash-realtime",
                        "qwen3-vl-rerank",
                        "qwen3-embedding"
                    ]
                    
                    for target_model in target_models:
                        model_found = False
                        for model in models_list:
                            model_id = model.get('id', '')
                            if target_model in model_id:
                                model_found = True
                                available_models.append(target_model)
                                print(f"  âœ… {target_model} - å¯ç”¨")
                                break
                        
                        if not model_found:
                            unavailable_models.append(target_model)
                            print(f"  âŒ {target_model} - ä¸å¯ç”¨")
                            
                elif 'models' in models_data and isinstance(models_data['models'], list):
                    # åŸå§‹æ ¼å¼
                    models_list = models_data['models']
                    print(f"ğŸ“Š æ‰¾åˆ° {len(models_list)} ä¸ªæ¨¡å‹ (åŸå§‹æ ¼å¼)")
                    
                    target_models = [
                        "qwen3-omni-flash-realtime",
                        "qwen3-vl-rerank",
                        "qwen3-embedding"
                    ]
                    
                    for target_model in target_models:
                        model_found = False
                        for model in models_list:
                            model_id = model.get('model', '')
                            if target_model in model_id:
                                model_found = True
                                available_models.append(target_model)
                                print(f"  âœ… {target_model} - å¯ç”¨")
                                break
                        
                        if not model_found:
                            unavailable_models.append(target_model)
                            print(f"  âŒ {target_model} - ä¸å¯ç”¨")
                else:
                    print(f"âš ï¸ æœªçŸ¥å“åº”æ ¼å¼: {models_data.keys()}")
                    # æ˜¾ç¤ºå®é™…å¯ç”¨çš„æ¨¡å‹
                    print("ğŸ” å®é™…å¯ç”¨çš„æ¨¡å‹:")
                    test_models = ["qwen-turbo", "qwen-plus", "qwen-max", "qwen-vl-plus"]
                    for test_model in test_models:
                        try:
                            test_response = requests.post(
                                f"{base_url}/compatible-mode/v1/chat/completions",
                                headers=headers,
                                json={
                                    "model": test_model,
                                    "messages": [{"role": "user", "content": "test"}],
                                    "max_tokens": 5
                                },
                                timeout=5
                            )
                            if test_response.status_code == 200:
                                available_models.append(test_model)
                                print(f"  âœ… {test_model} - å¯ç”¨")
                            else:
                                unavailable_models.append(test_model)
                                print(f"  âŒ {test_model} - ä¸å¯ç”¨")
                        except:
                            unavailable_models.append(test_model)
                            print(f"  âŒ {test_model} - æ£€æŸ¥å¤±è´¥")
                
                return {
                    "available": available_models,
                    "unavailable": unavailable_models,
                    "total_models": len(available_models) + len(unavailable_models)
                }
            else:
                return {
                    "available": [],
                    "unavailable": ["qwen3-omni-flash-realtime", "qwen3-vl-rerank", "qwen3-embedding"],
                    "error": f"APIè¯·æ±‚å¤±è´¥: {response.status_code}"
                }
                
        except requests.RequestException as e:
            return {
                "available": [],
                "unavailable": ["qwen3-omni-flash-realtime", "qwen3-vl-rerank", "qwen3-embedding"],
                "error": f"ç½‘ç»œè¯·æ±‚å¤±è´¥: {str(e)}"
            }
        
    except Exception as e:
        return {
            "available": [],
            "unavailable": ["qwen3-omni-flash-realtime", "qwen3-vl-rerank", "qwen3-embedding"],
            "error": f"æ£€æŸ¥æ¨¡å‹å¯ç”¨æ€§å¤±è´¥: {str(e)}"
        }

def check_actual_available_models():
    """æ£€æŸ¥å®é™…å¯ç”¨çš„æ¨¡å‹"""
    print("\n" + "=" * 60)
    print("ğŸ” æ£€æŸ¥å®é™…å¯ç”¨çš„æ¨¡å‹...")
    
    api_key = os.getenv("DASHSCOPE_API_KEY")
    if not api_key:
        print("âŒ æœªé…ç½®APIå¯†é’¥")
        return
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    # æµ‹è¯•å®é™…ä½¿ç”¨çš„æ¨¡å‹
    models_to_test = [
        ("qwen-turbo", "é€šç”¨ç¿»è¯‘æ¨¡å‹"),
        ("qwen-plus", "å¢å¼ºç¿»è¯‘æ¨¡å‹"),
        ("qwen-max", "é«˜æ€§èƒ½ç¿»è¯‘æ¨¡å‹"),
        ("qwen-vl-plus", "è§†è§‰è¯­è¨€æ¨¡å‹"),
        ("iic/emotion2vec_plus_large", "æƒ…æ„Ÿåˆ†ææ¨¡å‹"),
        ("wanx2.1-vace-plus", "è§†é¢‘ç¼–è¾‘æ¨¡å‹"),
        ("image-erase-completion", "å›¾åƒç¼–è¾‘æ¨¡å‹")
    ]
    
    available_models = []
    
    for model_name, description in models_to_test:
        print(f"\nğŸ” æµ‹è¯•æ¨¡å‹: {model_name} ({description})")
        try:
            # æ ¹æ®æ¨¡å‹ç±»å‹é€‰æ‹©ä¸åŒçš„æµ‹è¯•æ–¹æ³•
            if "chat" in model_name.lower() or model_name in ["qwen-turbo", "qwen-plus", "qwen-max", "qwen-vl-plus"]:
                # èŠå¤©æ¨¡å‹æµ‹è¯•
                response = requests.post(
                    "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions",
                    headers=headers,
                    json={
                        "model": model_name,
                        "messages": [{"role": "user", "content": "Hello"}],
                        "max_tokens": 10
                    },
                    timeout=10
                )
            elif "emotion" in model_name.lower():
                # æƒ…æ„Ÿåˆ†ææ¨¡å‹æµ‹è¯•
                response = requests.post(
                    "https://dashscope.aliyuncs.com/api/v1/services/inference/text-to-vector",
                    headers=headers,
                    json={
                        "model": model_name,
                        "input": {"text": "æµ‹è¯•æƒ…æ„Ÿåˆ†æ"}
                    },
                    timeout=10
                )
            elif "video" in model_name.lower() or "image" in model_name.lower():
                # è§†é¢‘/å›¾åƒç¼–è¾‘æ¨¡å‹æµ‹è¯•
                response = requests.post(
                    f"https://dashscope.aliyuncs.com/api/v1/services/{'video-editing' if 'video' in model_name.lower() else 'image-editing'}/{model_name}",
                    headers=headers,
                    json={
                        "model": model_name,
                        "input": {"prompt": "test"}
                    },
                    timeout=10
                )
            else:
                # å…¶ä»–æ¨¡å‹æµ‹è¯•
                response = requests.post(
                    "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions",
                    headers=headers,
                    json={
                        "model": model_name,
                        "messages": [{"role": "user", "content": "Hello"}],
                        "max_tokens": 10
                    },
                    timeout=10
                )
            
            if response.status_code == 200:
                available_models.append(model_name)
                print(f"  âœ… æ¨¡å‹å¯ç”¨")
            else:
                print(f"  âŒ æ¨¡å‹ä¸å¯ç”¨ - {response.text[:100]}")
                
        except Exception as e:
            print(f"  âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
    
    print(f"\nğŸ“Š å®é™…å¯ç”¨æ¨¡å‹æ€»ç»“:")
    print(f"  å¯ç”¨æ¨¡å‹æ•°é‡: {len(available_models)}")
    print(f"  å¯ç”¨æ¨¡å‹åˆ—è¡¨: {available_models}")

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹ä¿®å¤åçš„æ¨¡å‹å¯ç”¨æ€§æ£€æŸ¥")
    print("=" * 60)
    
    # æµ‹è¯•ä¿®å¤åçš„é€»è¾‘
    result = check_model_availability_fixed()
    print(f"\nğŸ“Š ä¿®å¤åçš„æ£€æŸ¥ç»“æœ:")
    print(f"  å¯ç”¨æ¨¡å‹: {result.get('available', [])}")
    print(f"  ä¸å¯ç”¨æ¨¡å‹: {result.get('unavailable', [])}")
    print(f"  æ€»æ¨¡å‹æ•°: {result.get('total_models', 0)}")
    print(f"  é”™è¯¯ä¿¡æ¯: {result.get('error', 'æ— ')}")
    
    check_actual_available_models()
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æµ‹è¯•å®Œæˆ")
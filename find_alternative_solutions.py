#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸ºä¸å¯ç”¨çš„åŠŸèƒ½æ¨¡å—å¯»æ‰¾æ›¿ä»£æ–¹æ¡ˆ
"""

import os
import sys
import json
import logging
import requests

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def find_alternative_models():
    """ä¸ºä¸å¯ç”¨çš„æ¨¡å—å¯»æ‰¾æ›¿ä»£æ¨¡å‹"""
    print("ğŸ” ä¸ºä¸å¯ç”¨çš„åŠŸèƒ½æ¨¡å—å¯»æ‰¾æ›¿ä»£æ–¹æ¡ˆ...")
    print("=" * 80)
    
    api_key = os.getenv("DASHSCOPE_API_KEY")
    if not api_key:
        print("âŒ æœªé…ç½®DASHSCOPE_API_KEYç¯å¢ƒå˜é‡")
        return
    
    headers = {
        "Authorization": f"Bearer {api_key}",
        "Content-Type": "application/json"
    }
    
    # ä¸å¯ç”¨çš„æ¨¡å—åŠå…¶å¯èƒ½çš„æ›¿ä»£æ–¹æ¡ˆ
    unavailable_modules = [
        {
            "name": "æƒ…æ„Ÿåˆ†ææ¨¡å—",
            "original_model": "iic/emotion2vec_plus_large",
            "alternatives": [
                {
                    "model": "qwen-turbo",
                    "description": "ä½¿ç”¨é€šç”¨æ¨¡å‹è¿›è¡Œæƒ…æ„Ÿåˆ†æ",
                    "test_input": "è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘ï¼šæˆ‘ä»Šå¤©å¾ˆå¼€å¿ƒ",
                    "endpoint": "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"
                },
                {
                    "model": "qwen-plus", 
                    "description": "ä½¿ç”¨å¢å¼ºæ¨¡å‹è¿›è¡Œæƒ…æ„Ÿåˆ†æ",
                    "test_input": "è¯·åˆ†æä»¥ä¸‹æ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘ï¼šæˆ‘ä»Šå¤©å¾ˆå¼€å¿ƒ",
                    "endpoint": "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"
                }
            ]
        },
        {
            "name": "è§†é¢‘å­—å¹•å‹åˆ¶æ¨¡å—",
            "original_model": "wanx2.1-vace-plus",
            "alternatives": [
                {
                    "model": "qwen-vl-plus",
                    "description": "ä½¿ç”¨è§†è§‰è¯­è¨€æ¨¡å‹è¿›è¡Œè§†é¢‘å¤„ç†",
                    "test_input": "è¯·ä¸ºè§†é¢‘æ·»åŠ å­—å¹•",
                    "endpoint": "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"
                }
            ]
        },
        {
            "name": "å­—å¹•æ“¦é™¤æ¨¡å—",
            "original_model": "image-erase-completion",
            "alternatives": [
                {
                    "model": "qwen-vl-plus",
                    "description": "ä½¿ç”¨è§†è§‰è¯­è¨€æ¨¡å‹è¿›è¡Œå›¾åƒå¤„ç†",
                    "test_input": "è¯·æ“¦é™¤å›¾åƒä¸­çš„å­—å¹•",
                    "endpoint": "https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions"
                }
            ]
        }
    ]
    
    results = []
    
    for module in unavailable_modules:
        print(f"\nğŸ“‹ {module['name']}")
        print(f"   ğŸ¯ åŸå§‹æ¨¡å‹: {module['original_model']}")
        print(f"   ğŸ” å¯»æ‰¾æ›¿ä»£æ–¹æ¡ˆ...")
        
        module_result = {
            "module_name": module['name'],
            "original_model": module['original_model'],
            "best_alternative": None,
            "alternatives_tested": []
        }
        
        for alternative in module['alternatives']:
            print(f"   ğŸ§ª æµ‹è¯•æ›¿ä»£æ¨¡å‹: {alternative['model']}")
            print(f"      ğŸ“ æè¿°: {alternative['description']}")
            
            alternative_result = {
                "model": alternative['model'],
                "description": alternative['description'],
                "status": "âŒ æœªæµ‹è¯•",
                "error": None,
                "response_time": None,
                "sample_response": None
            }
            
            try:
                start_time = time.time()
                
                if "chat" in alternative['model'].lower() or alternative['model'] in ["qwen-turbo", "qwen-plus", "qwen-max", "qwen-vl-plus"]:
                    response = requests.post(
                        alternative['endpoint'],
                        headers=headers,
                        json={
                            "model": alternative['model'],
                            "messages": [{"role": "user", "content": alternative['test_input']}],
                            "max_tokens": 100
                        },
                        timeout=15
                    )
                    end_time = time.time()
                    alternative_result['response_time'] = round(end_time - start_time, 2)
                    
                    if response.status_code == 200:
                        alternative_result['status'] = "âœ… å¯ç”¨"
                        try:
                            response_data = response.json()
                            if 'choices' in response_data and len(response_data['choices']) > 0:
                                content = response_data['choices'][0]['message']['content']
                                alternative_result['sample_response'] = content[:150] + "..." if len(content) > 150 else content
                        except:
                            alternative_result['sample_response'] = "å“åº”è§£æå¤±è´¥"
                    else:
                        alternative_result['status'] = "âŒ ä¸å¯ç”¨"
                        alternative_result['error'] = f"çŠ¶æ€ç : {response.status_code}, é”™è¯¯: {response.text[:200]}"
                
                else:
                    alternative_result['status'] = "âŒ ä¸æ”¯æŒ"
                    alternative_result['error'] = "ä¸æ”¯æŒçš„æ¨¡å‹ç±»å‹"
                
            except Exception as e:
                alternative_result['status'] = "âŒ æµ‹è¯•å¤±è´¥"
                alternative_result['error'] = str(e)
            
            module_result['alternatives_tested'].append(alternative_result)
            print(f"      ğŸ“Š çŠ¶æ€: {alternative_result['status']}")
            if alternative_result['response_time']:
                print(f"      â±ï¸ å“åº”æ—¶é—´: {alternative_result['response_time']}ç§’")
            if alternative_result.get('sample_response'):
                print(f"      ğŸ“ ç¤ºä¾‹å“åº”: {alternative_result['sample_response']}")
        
        # é€‰æ‹©æœ€ä½³æ›¿ä»£æ–¹æ¡ˆ
        available_alternatives = [alt for alt in module_result['alternatives_tested'] if alt['status'] == "âœ… å¯ç”¨"]
        if available_alternatives:
            best_alternative = available_alternatives[0]  # é€‰æ‹©ç¬¬ä¸€ä¸ªå¯ç”¨çš„æ›¿ä»£æ–¹æ¡ˆ
            module_result['best_alternative'] = best_alternative
            print(f"   ğŸ† æœ€ä½³æ›¿ä»£æ–¹æ¡ˆ: {best_alternative['model']} - {best_alternative['description']}")
        else:
            print(f"   âŒ æœªæ‰¾åˆ°å¯ç”¨çš„æ›¿ä»£æ–¹æ¡ˆ")
        
        results.append(module_result)
    
    return results

def generate_recommendation_report(results):
    """ç”Ÿæˆå»ºè®®æŠ¥å‘Š"""
    print("\n" + "=" * 80)
    print("ğŸ“‹ æ›¿ä»£æ–¹æ¡ˆå»ºè®®æŠ¥å‘Š")
    print("=" * 80)
    
    for i, result in enumerate(results, 1):
        print(f"\n{i}. {result['module_name']}")
        print(f"   ğŸ¯ åŸå§‹æ¨¡å‹: {result['original_model']}")
        
        if result['best_alternative']:
            best = result['best_alternative']
            print(f"   ğŸ† æ¨èæ›¿ä»£æ–¹æ¡ˆ:")
            print(f"      ğŸ¤– æ¨¡å‹: {best['model']}")
            print(f"      ğŸ“ æè¿°: {best['description']}")
            print(f"      âœ… çŠ¶æ€: å¯ç”¨")
            print(f"      â±ï¸ å“åº”æ—¶é—´: {best['response_time']}ç§’")
            print(f"      ğŸ“ ç¤ºä¾‹: {best['sample_response']}")
            
            # æä¾›å®æ–½å»ºè®®
            if "æƒ…æ„Ÿåˆ†æ" in result['module_name']:
                print(f"   ğŸ’¡ å®æ–½å»ºè®®:")
                print(f"      - ä½¿ç”¨ {best['model']} è¿›è¡Œæ–‡æœ¬æƒ…æ„Ÿåˆ†æ")
                print(f"      - æä¾›æ˜ç¡®çš„æƒ…æ„Ÿåˆ†ææŒ‡ä»¤")
                print(f"      - å¯ä»¥åˆ†æç§¯æã€æ¶ˆæã€ä¸­æ€§ç­‰æƒ…æ„Ÿ")
            elif "è§†é¢‘å­—å¹•å‹åˆ¶" in result['module_name']:
                print(f"   ğŸ’¡ å®æ–½å»ºè®®:")
                print(f"      - ä½¿ç”¨ {best['model']} è¿›è¡Œè§†é¢‘å­—å¹•å¤„ç†")
                print(f"      - æä¾›è¯¦ç»†çš„å­—å¹•æ·»åŠ æŒ‡ä»¤")
                print(f"      - å¯ä»¥å¤„ç†å­—å¹•æ ·å¼ã€ä½ç½®ç­‰")
            elif "å­—å¹•æ“¦é™¤" in result['module_name']:
                print(f"   ğŸ’¡ å®æ–½å»ºè®®:")
                print(f"      - ä½¿ç”¨ {best['model']} è¿›è¡Œå›¾åƒå­—å¹•æ“¦é™¤")
                print(f"      - æä¾›å­—å¹•åŒºåŸŸæè¿°")
                print(f"      - å¯ä»¥å¤„ç†å¤æ‚çš„å­—å¹•èƒŒæ™¯")
        else:
            print(f"   âŒ æ— å¯ç”¨æ›¿ä»£æ–¹æ¡ˆ")
            print(f"   ğŸ’¡ å»ºè®®:")
            print(f"      - æš‚æ—¶ç¦ç”¨è¯¥åŠŸèƒ½æ¨¡å—")
            print(f"      - è”ç³»APIæä¾›å•†è·å–æ­£ç¡®çš„æ¨¡å‹ä¿¡æ¯")
            print(f"      - è€ƒè™‘ä½¿ç”¨ç¬¬ä¸‰æ–¹æœåŠ¡")
    
    # æ€»ç»“
    total_modules = len(results)
    modules_with_solutions = len([r for r in results if r['best_alternative']])
    modules_without_solutions = total_modules - modules_with_solutions
    
    print(f"\n" + "=" * 80)
    print(f"ğŸ“Š æ›¿ä»£æ–¹æ¡ˆæ€»ç»“:")
    print(f"   ğŸ“‹ æ€»é—®é¢˜æ¨¡å—æ•°: {total_modules}")
    print(f"   âœ… æœ‰è§£å†³æ–¹æ¡ˆ: {modules_with_solutions}")
    print(f"   âŒ æ— è§£å†³æ–¹æ¡ˆ: {modules_without_solutions}")
    print(f"   ğŸ“Š è§£å†³ç‡: {round(modules_with_solutions/total_modules*100, 1)}%")
    
    if modules_with_solutions == total_modules:
        print(f"ğŸ‰ æ‰€æœ‰æ¨¡å—éƒ½æœ‰å¯ç”¨çš„æ›¿ä»£æ–¹æ¡ˆï¼")
    elif modules_with_solutions > 0:
        print(f"âš ï¸ éƒ¨åˆ†æ¨¡å—æœ‰æ›¿ä»£æ–¹æ¡ˆï¼Œå¯ä»¥ç»§ç»­å¼€å‘")
    else:
        print(f"âŒ æ‰€æœ‰æ¨¡å—éƒ½æ— æ›¿ä»£æ–¹æ¡ˆï¼Œéœ€è¦é‡æ–°è€ƒè™‘æ¶æ„")

if __name__ == "__main__":
    import time
    
    print("ğŸš€ å¼€å§‹ä¸ºä¸å¯ç”¨çš„åŠŸèƒ½æ¨¡å—å¯»æ‰¾æ›¿ä»£æ–¹æ¡ˆ")
    print("=" * 80)
    
    # å¯»æ‰¾æ›¿ä»£æ–¹æ¡ˆ
    results = find_alternative_models()
    
    # ç”Ÿæˆå»ºè®®æŠ¥å‘Š
    generate_recommendation_report(results)
    
    print("\n" + "=" * 80)
    print("ğŸ‰ æ›¿ä»£æ–¹æ¡ˆåˆ†æå®Œæˆ")
    print("=" * 80)
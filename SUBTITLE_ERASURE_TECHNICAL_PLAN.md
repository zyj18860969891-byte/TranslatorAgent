# ğŸ­ å­—å¹•æ— ç—•æ“¦é™¤æŠ€æœ¯æ–¹æ¡ˆ - 2024å¹´1æœˆ20æ—¥

## ğŸ“‹ æŠ€æœ¯æ–¹æ¡ˆæ¦‚è¿°

**åŠŸèƒ½åç§°**: å­—å¹•æ— ç—•æ“¦é™¤ (Subtitle Video Erasure)  
**ä¼˜å…ˆçº§**: ä¸­ä¼˜å…ˆçº§  
**é¢„è®¡æ—¶é—´**: 1-2ä¸ªæœˆ  
**æŠ€æœ¯æ–¹æ¡ˆ**: æ‰©æ•£æ¨¡å‹ + æ©ç ç”Ÿæˆ + èƒŒæ™¯é‡å»º  
**ç›®æ ‡**: å®ç°ç”»é¢åƒç´ çº§çš„æ— ç—•ä¿®å¤ï¼Œä¸ºæ–°å­—å¹•çš„å‹åˆ¶æä¾›å¹²å‡€çš„è§†è§‰èƒŒæ™¯

## ğŸ¯ åŠŸèƒ½éœ€æ±‚åˆ†æ

### 1. æ ¸å¿ƒåŠŸèƒ½
- åœ¨å‹åˆ¶æ–°å­—å¹•å‰ï¼Œå…ˆå°†è§†é¢‘åŸæœ‰çš„ç¡¬ç¼–ç å­—å¹•è¿›è¡Œè§†è§‰æ¶ˆé™¤
- é‡æ„èƒŒæ™¯çº¹ç†ï¼Œä¸ºæ–°å­—å¹•çš„å‹åˆ¶æä¾›å¹²å‡€çš„è§†è§‰èƒŒæ™¯
- å®ç°ç”»é¢åƒç´ çº§çš„æ— ç—•ä¿®å¤
- ä¿æŒè§†é¢‘çš„æ—¶é—´ä¸€è‡´æ€§

### 2. æŠ€æœ¯æŒ‘æˆ˜
- éœ€è¦å‡†ç¡®è¯†åˆ«å­—å¹•åŒºåŸŸ
- éœ€è¦é«˜è´¨é‡çš„èƒŒæ™¯é‡å»º
- éœ€è¦ä¿æŒè§†é¢‘çš„æ—¶é—´ä¸€è‡´æ€§
- éœ€è¦å¤„ç†å¤æ‚çš„èƒŒæ™¯çº¹ç†

### 3. è§£å†³æ–¹æ¡ˆ
- é‡‡ç”¨SOTAçº§åˆ«çš„xingzi/diffuEraseræ‰©æ•£æ¨¡å‹
- ç”±è§†è§‰æ¨¡å‹ç”Ÿæˆå­—å¹•ä½ç½®çš„æ©ç ï¼ˆMaskï¼‰
- ç”±æ“¦é™¤å·¥å…·è¿›è¡ŒèƒŒæ™¯é‡å»º
- æ‰©æ•£æ¨¡å‹å®ç°åƒç´ çº§çš„æ— ç—•ä¿®å¤

## ğŸ”§ æŠ€æœ¯æ¶æ„è®¾è®¡

### 1. æ•´ä½“æ¶æ„
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    å­—å¹•æ— ç—•æ“¦é™¤ç³»ç»Ÿ                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚  å­—å¹•æ£€æµ‹   â”‚    â”‚  æ©ç ç”Ÿæˆ   â”‚    â”‚  èƒŒæ™¯é‡å»º   â”‚     â”‚
â”‚  â”‚   æ¨¡å—      â”‚â”€â”€â”€â”€â”‚   æ¨¡å—      â”‚â”€â”€â”€â”€â”‚   æ¨¡å—      â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â”‚                   â”‚                   â”‚           â”‚
â”‚         â–¼                   â–¼                   â–¼           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              æ‰©æ•£æ¨¡å‹ç®¡ç†å™¨                         â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. æ¨¡å—è®¾è®¡

#### 2.1 å­—å¹•æ£€æµ‹æ¨¡å— (SubtitleDetector)
**èŒè´£**: æ£€æµ‹è§†é¢‘ä¸­ç¡¬ç¼–ç å­—å¹•çš„ä½ç½®å’ŒèŒƒå›´
**åŠŸèƒ½**:
- å¸§å·®åˆ†æ³•æ£€æµ‹å­—å¹•åŒºåŸŸ
- æ–‡æœ¬æ£€æµ‹ç®—æ³•è¯†åˆ«å­—å¹•è¾¹ç•Œ
- æ—¶é—´è½´åŒæ­¥ï¼Œç¡®å®šå­—å¹•å‡ºç°å’Œæ¶ˆå¤±æ—¶é—´
- å¤„ç†åŠ¨æ€å­—å¹•ï¼ˆç§»åŠ¨ã€ç¼©æ”¾ï¼‰

#### 2.2 æ©ç ç”Ÿæˆæ¨¡å— (MaskGenerator)
**èŒè´£**: ç”Ÿæˆå­—å¹•åŒºåŸŸçš„ç²¾ç¡®æ©ç 
**åŠŸèƒ½**:
- åŸºäºæ£€æµ‹ç»“æœç”ŸæˆäºŒå€¼æ©ç 
- æ©ç è¾¹ç¼˜ä¼˜åŒ–ï¼ˆå¹³æ»‘ã€è†¨èƒ€ã€è…èš€ï¼‰
- æ—¶é—´ä¸€è‡´æ€§å¤„ç†
- æ©ç è´¨é‡éªŒè¯

#### 2.3 èƒŒæ™¯é‡å»ºæ¨¡å— (BackgroundReconstructor)
**èŒè´£**: ä½¿ç”¨æ‰©æ•£æ¨¡å‹é‡å»ºå­—å¹•åŒºåŸŸçš„èƒŒæ™¯
**åŠŸèƒ½**:
- è°ƒç”¨diffuEraseræ‰©æ•£æ¨¡å‹
- ç”Ÿæˆé«˜è´¨é‡èƒŒæ™¯çº¹ç†
- è¾¹ç¼˜èåˆå¤„ç†
- æ—¶é—´ä¸€è‡´æ€§ä¿æŒ

#### 2.4 æ‰©æ•£æ¨¡å‹ç®¡ç†å™¨ (DiffusionModelManager)
**èŒè´£**: ç®¡ç†æ‰©æ•£æ¨¡å‹çš„åŠ è½½å’Œæ¨ç†
**åŠŸèƒ½**:
- æ¨¡å‹åŠ è½½å’Œåˆå§‹åŒ–
- æ¨ç†å‚æ•°é…ç½®
- GPU/CPUèµ„æºç®¡ç†
- æ¨¡å‹æ€§èƒ½ä¼˜åŒ–

## ğŸ› ï¸ æŠ€æœ¯å®ç°æ–¹æ¡ˆ

### 1. å­—å¹•æ£€æµ‹æ–¹æ¡ˆ

#### 1.1 å¸§å·®åˆ†æ³•æ£€æµ‹
```python
# å¸§å·®åˆ†æ³•æ£€æµ‹å­—å¹•åŒºåŸŸ
def detect_subtitle_region(video_path: str, frame_interval: int = 30) -> List[Dict]:
    """
    ä½¿ç”¨å¸§å·®åˆ†æ³•æ£€æµ‹å­—å¹•åŒºåŸŸ
    
    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        frame_interval: å¸§é—´éš”ï¼ˆç”¨äºæ£€æµ‹å˜åŒ–ï¼‰
        
    Returns:
        å­—å¹•åŒºåŸŸåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ä½ç½®å’Œæ—¶é—´ä¿¡æ¯
    """
    import cv2
    import numpy as np
    
    cap = cv2.VideoCapture(video_path)
    regions = []
    
    prev_frame = None
    frame_count = 0
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
            
        if frame_count % frame_interval == 0:
            if prev_frame is not None:
                # è®¡ç®—å¸§å·®
                diff = cv2.absdiff(frame, prev_frame)
                gray = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)
                _, binary = cv2.threshold(gray, 30, 255, cv2.THRESH_BINARY)
                
                # æŸ¥æ‰¾è½®å»“
                contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                
                for contour in contours:
                    area = cv2.contourArea(contour)
                    if area > 100:  # è¿‡æ»¤å°åŒºåŸŸ
                        x, y, w, h = cv2.boundingRect(contour)
                        # è¿›ä¸€æ­¥ç­›é€‰å­—å¹•åŒºåŸŸç‰¹å¾
                        if self._is_subtitle_region(x, y, w, h, frame.shape):
                            regions.append({
                                'x': x, 'y': y, 'w': w, 'h': h,
                                'frame': frame_count,
                                'timestamp': frame_count / cap.get(cv2.CAP_PROP_FPS)
                            })
            
            prev_frame = frame.copy()
        
        frame_count += 1
    
    cap.release()
    return regions

def _is_subtitle_region(self, x: int, y: int, w: int, h: int, frame_shape: tuple) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸ºå­—å¹•åŒºåŸŸ"""
    frame_height, frame_width = frame_shape[:2]
    
    # å­—å¹•é€šå¸¸ä½äºåº•éƒ¨1/3åŒºåŸŸ
    if y < frame_height * 2/3:
        return False
    
    # å­—å¹•åŒºåŸŸé€šå¸¸ä¸ºæ°´å¹³é•¿æ¡å½¢
    aspect_ratio = w / h
    if aspect_ratio < 2 or aspect_ratio > 20:
        return False
    
    # åŒºåŸŸå¤§å°é€‚ä¸­
    area = w * h
    if area < 500 or area > frame_width * frame_height * 0.1:
        return False
    
    return True
```

#### 1.2 æ–‡æœ¬æ£€æµ‹ç®—æ³•
```python
# ä½¿ç”¨æ–‡æœ¬æ£€æµ‹æ¨¡å‹
def detect_text_regions(video_path: str) -> List[Dict]:
    """
    ä½¿ç”¨æ–‡æœ¬æ£€æµ‹æ¨¡å‹è¯†åˆ«å­—å¹•åŒºåŸŸ
    
    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        
    Returns:
        æ–‡æœ¬åŒºåŸŸåˆ—è¡¨
    """
    # å¯ä»¥ä½¿ç”¨EASTã€DBç­‰æ–‡æœ¬æ£€æµ‹ç®—æ³•
    # æˆ–è€…ä½¿ç”¨OCRæ¨¡å‹è¿›è¡Œæ–‡æœ¬æ£€æµ‹
    pass
```

### 2. æ©ç ç”Ÿæˆæ–¹æ¡ˆ

#### 2.1 äºŒå€¼æ©ç ç”Ÿæˆ
```python
# ç”Ÿæˆå­—å¹•åŒºåŸŸæ©ç 
def generate_subtitle_mask(frame_shape: tuple, subtitle_regions: List[Dict]) -> np.ndarray:
    """
    ç”Ÿæˆå­—å¹•åŒºåŸŸçš„äºŒå€¼æ©ç 
    
    Args:
        frame_shape: å¸§å½¢çŠ¶ (H, W, C)
        subtitle_regions: å­—å¹•åŒºåŸŸåˆ—è¡¨
        
    Returns:
        äºŒå€¼æ©ç  (H, W)
    """
    import numpy as np
    
    height, width = frame_shape[:2]
    mask = np.zeros((height, width), dtype=np.uint8)
    
    for region in subtitle_regions:
        x, y, w, h = region['x'], region['y'], region['w'], region['h']
        # å¡«å……å­—å¹•åŒºåŸŸ
        mask[y:y+h, x:x+w] = 255
    
    return mask

# æ©ç ä¼˜åŒ–
def optimize_mask(mask: np.ndarray, kernel_size: int = 5) -> np.ndarray:
    """
    ä¼˜åŒ–æ©ç è¾¹ç¼˜
    
    Args:
        mask: è¾“å…¥æ©ç 
        kernel_size: å·ç§¯æ ¸å¤§å°
        
    Returns:
        ä¼˜åŒ–åçš„æ©ç 
    """
    import cv2
    import numpy as np
    
    # è†¨èƒ€æ“ä½œï¼Œæ‰©å¤§æ©ç åŒºåŸŸ
    kernel = np.ones((kernel_size, kernel_size), np.uint8)
    mask_dilated = cv2.dilate(mask, kernel, iterations=1)
    
    # é«˜æ–¯æ¨¡ç³Šï¼Œå¹³æ»‘è¾¹ç¼˜
    mask_blurred = cv2.GaussianBlur(mask_dilated, (kernel_size*2+1, kernel_size*2+1), 0)
    
    return mask_blurred
```

### 3. æ‰©æ•£æ¨¡å‹é›†æˆæ–¹æ¡ˆ

#### 3.1 æ¨¡å‹é€‰æ‹©
- **æ¨èæ¨¡å‹**: xingzi/diffuEraser
- **æ¨¡å‹ç‰¹ç‚¹**: 
  - SOTAçº§åˆ«çš„å›¾åƒä¿®å¤æ¨¡å‹
  - æ”¯æŒè§†é¢‘ä¿®å¤ï¼Œä¿æŒæ—¶é—´ä¸€è‡´æ€§
  - åŸºäºæ‰©æ•£æ¨¡å‹ï¼Œç”Ÿæˆè´¨é‡é«˜
  - æ”¯æŒæ©ç å¼•å¯¼çš„ä¿®å¤

#### 3.2 æ¨¡å‹åŠ è½½å’Œæ¨ç†
```python
# æ‰©æ•£æ¨¡å‹ç®¡ç†å™¨
class DiffusionModelManager:
    def __init__(self, model_name: str = "xingzi/diffuEraser"):
        """
        åˆå§‹åŒ–æ‰©æ•£æ¨¡å‹ç®¡ç†å™¨
        
        Args:
            model_name: æ¨¡å‹åç§°
        """
        self.model_name = model_name
        self.model = None
        self.device = self._detect_device()
        
    def _detect_device(self) -> str:
        """æ£€æµ‹å¯ç”¨è®¾å¤‡"""
        try:
            import torch
            if torch.cuda.is_available():
                return "cuda"
            elif torch.backends.mps.is_available():
                return "mps"
            else:
                return "cpu"
        except ImportError:
            return "cpu"
    
    def load_model(self):
        """åŠ è½½æ¨¡å‹"""
        try:
            # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„diffuEraseræ¨¡å‹APIè¿›è¡Œè°ƒæ•´
            # å¯èƒ½éœ€è¦ä½¿ç”¨Hugging Faceçš„transformersåº“
            from transformers import AutoModelForImageSegmentation
            
            self.model = AutoModelForImageSegmentation.from_pretrained(
                self.model_name,
                trust_remote_code=True
            )
            self.model.to(self.device)
            self.model.eval()
            
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ: {self.model_name}")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            raise
    
    def erase_subtitle(self, image: np.ndarray, mask: np.ndarray) -> np.ndarray:
        """
        ä½¿ç”¨æ‰©æ•£æ¨¡å‹æ“¦é™¤å­—å¹•
        
        Args:
            image: è¾“å…¥å›¾åƒ (H, W, C)
            mask: æ©ç  (H, W)
            
        Returns:
            ä¿®å¤åçš„å›¾åƒ (H, W, C)
        """
        import torch
        import numpy as np
        from PIL import Image
        
        # é¢„å¤„ç†
        image_pil = Image.fromarray(image)
        mask_pil = Image.fromarray(mask)
        
        # è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼
        # è¿™é‡Œéœ€è¦æ ¹æ®å…·ä½“æ¨¡å‹çš„è¾“å…¥è¦æ±‚è¿›è¡Œè°ƒæ•´
        inputs = self._preprocess(image_pil, mask_pil)
        
        # æ¨ç†
        with torch.no_grad():
            outputs = self.model(**inputs)
        
        # åå¤„ç†
        result = self._postprocess(outputs)
        
        return result
    
    def _preprocess(self, image: Image.Image, mask: Image.Image):
        """é¢„å¤„ç†è¾“å…¥æ•°æ®"""
        # æ ¹æ®å…·ä½“æ¨¡å‹çš„é¢„å¤„ç†è¦æ±‚å®ç°
        pass
    
    def _postprocess(self, outputs):
        """åå¤„ç†è¾“å‡ºæ•°æ®"""
        # æ ¹æ®å…·ä½“æ¨¡å‹çš„è¾“å‡ºæ ¼å¼å®ç°
        pass
```

#### 3.3 è§†é¢‘å¸§å¤„ç†
```python
# è§†é¢‘å­—å¹•æ“¦é™¤å¤„ç†
def erase_subtitles_from_video(video_path: str, output_path: str, model_manager: DiffusionModelManager):
    """
    ä»è§†é¢‘ä¸­æ“¦é™¤å­—å¹•
    
    Args:
        video_path: è¾“å…¥è§†é¢‘è·¯å¾„
        output_path: è¾“å‡ºè§†é¢‘è·¯å¾„
        model_manager: æ‰©æ•£æ¨¡å‹ç®¡ç†å™¨
    """
    import cv2
    import numpy as np
    
    cap = cv2.VideoCapture(video_path)
    fps = cap.get(cv2.CAP_PROP_FPS)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    
    # åˆ›å»ºè§†é¢‘å†™å…¥å™¨
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    frame_count = 0
    prev_mask = None
    
    while True:
        ret, frame = cap.read()
        if not ret:
            break
        
        # æ£€æµ‹å­—å¹•åŒºåŸŸ
        subtitle_regions = detect_subtitle_region_frame(frame, prev_mask)
        
        if subtitle_regions:
            # ç”Ÿæˆæ©ç 
            mask = generate_subtitle_mask(frame.shape, subtitle_regions)
            mask = optimize_mask(mask)
            
            # ä½¿ç”¨æ‰©æ•£æ¨¡å‹ä¿®å¤
            frame_fixed = model_manager.erase_subtitle(frame, mask)
            
            # æ›´æ–°å‰ä¸€å¸§æ©ç 
            prev_mask = mask
        else:
            frame_fixed = frame
        
        # å†™å…¥å¸§
        out.write(frame_fixed)
        
        frame_count += 1
        if frame_count % 100 == 0:
            print(f"å·²å¤„ç† {frame_count} å¸§")
    
    cap.release()
    out.release()
    print(f"âœ… è§†é¢‘å¤„ç†å®Œæˆï¼Œè¾“å‡º: {output_path}")
```

### 4. æ—¶é—´ä¸€è‡´æ€§ä¿æŒ

#### 4.1 å¸§é—´ä¸€è‡´æ€§
```python
# ä¿æŒæ—¶é—´ä¸€è‡´æ€§
def maintain_temporal_consistency(frames: List[np.ndarray], masks: List[np.ndarray]) -> List[np.ndarray]:
    """
    ä¿æŒè§†é¢‘å¸§é—´çš„æ—¶é—´ä¸€è‡´æ€§
    
    Args:
        frames: å¸§åˆ—è¡¨
        masks: æ©ç åˆ—è¡¨
        
    Returns:
        ä¿®å¤åçš„å¸§åˆ—è¡¨
    """
    import numpy as np
    
    processed_frames = []
    
    for i, (frame, mask) in enumerate(zip(frames, masks)):
        if i == 0:
            # ç¬¬ä¸€å¸§ç›´æ¥å¤„ç†
            processed_frame = process_frame_with_context(frame, mask, None)
        else:
            # ä½¿ç”¨å‰ä¸€å¸§ä½œä¸ºä¸Šä¸‹æ–‡
            prev_frame = processed_frames[i-1]
            processed_frame = process_frame_with_context(frame, mask, prev_frame)
        
        processed_frames.append(processed_frame)
    
    return processed_frames

def process_frame_with_context(frame: np.ndarray, mask: np.ndarray, prev_frame: np.ndarray = None) -> np.ndarray:
    """
    ä½¿ç”¨ä¸Šä¸‹æ–‡ä¿¡æ¯å¤„ç†å¸§
    
    Args:
        frame: å½“å‰å¸§
        mask: å½“å‰å¸§æ©ç 
        prev_frame: å‰ä¸€å¸§ï¼ˆç”¨äºæ—¶é—´ä¸€è‡´æ€§ï¼‰
        
    Returns:
        ä¿®å¤åçš„å¸§
    """
    # å¦‚æœæœ‰å‰ä¸€å¸§ï¼Œå¯ä»¥ä½¿ç”¨å…‰æµæˆ–è¿åŠ¨ä¼°è®¡æ¥ä¿æŒä¸€è‡´æ€§
    if prev_frame is not None:
        # è®¡ç®—å…‰æµ
        flow = calculate_optical_flow(prev_frame, frame)
        # ä½¿ç”¨å…‰æµæŒ‡å¯¼ä¿®å¤
        return repair_with_flow(frame, mask, flow)
    else:
        # ç›´æ¥ä¿®å¤
        return repair_frame(frame, mask)
```

#### 4.2 å…‰æµè®¡ç®—
```python
# è®¡ç®—å…‰æµ
def calculate_optical_flow(prev_frame: np.ndarray, curr_frame: np.ndarray) -> np.ndarray:
    """
    è®¡ç®—ä¸¤å¸§ä¹‹é—´çš„å…‰æµ
    
    Args:
        prev_frame: å‰ä¸€å¸§
        curr_frame: å½“å‰å¸§
        
    Returns:
        å…‰æµåœº (H, W, 2)
    """
    import cv2
    import numpy as np
    
    # è½¬æ¢ä¸ºç°åº¦å›¾
    prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)
    curr_gray = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2GRAY)
    
    # è®¡ç®—å…‰æµ
    flow = cv2.calcOpticalFlowFarneback(
        prev_gray, curr_gray, None,
        pyr_scale=0.5, levels=3, winsize=15,
        iterations=3, poly_n=5, poly_sigma=1.2, flags=0
    )
    
    return flow
```

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–æ–¹æ¡ˆ

### 1. æ¨¡å‹ä¼˜åŒ–
```python
# æ¨¡å‹ä¼˜åŒ–ç­–ç•¥
optimization_strategies = {
    "quantization": {
        "description": "æ¨¡å‹é‡åŒ–ï¼Œå‡å°‘å†…å­˜å ç”¨",
        "implementation": "ä½¿ç”¨FP16æˆ–INT8é‡åŒ–",
        "expected_improvement": "å†…å­˜å ç”¨å‡å°‘50%ï¼Œæ¨ç†é€Ÿåº¦æå‡2å€"
    },
    "pruning": {
        "description": "æ¨¡å‹å‰ªæï¼Œå‡å°‘è®¡ç®—é‡",
        "implementation": "ç§»é™¤ä¸é‡è¦çš„æƒé‡",
        "expected_improvement": "è®¡ç®—é‡å‡å°‘30%ï¼Œé€Ÿåº¦æå‡1.5å€"
    },
    "distillation": {
        "description": "çŸ¥è¯†è’¸é¦ï¼Œä½¿ç”¨å°æ¨¡å‹",
        "implementation": "è®­ç»ƒè½»é‡çº§å­¦ç”Ÿæ¨¡å‹",
        "expected_improvement": "æ¨¡å‹å¤§å°å‡å°‘70%ï¼Œé€Ÿåº¦æå‡3å€"
    },
    "batch_processing": {
        "description": "æ‰¹é‡å¤„ç†ï¼Œæé«˜ååé‡",
        "implementation": "åŒæ—¶å¤„ç†å¤šä¸ªå¸§",
        "expected_improvement": "ååé‡æå‡2-4å€"
    }
}
```

### 2. å†…å­˜ä¼˜åŒ–
```python
# å†…å­˜ä¼˜åŒ–ç­–ç•¥
memory_optimization = {
    "streaming": {
        "description": "æµå¼å¤„ç†ï¼Œé¿å…ä¸€æ¬¡æ€§åŠ è½½æ•´ä¸ªè§†é¢‘",
        "implementation": "é€å¸§å¤„ç†ï¼ŒåŠæ—¶é‡Šæ”¾å†…å­˜"
    },
    "temp_file": {
        "description": "ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶å­˜å‚¨ä¸­é—´ç»“æœ",
        "implementation": "å°†ä¸­é—´å¸§ä¿å­˜åˆ°ç£ç›˜"
    },
    "gpu_memory": {
        "description": "ä¼˜åŒ–GPUå†…å­˜ä½¿ç”¨",
        "implementation": "ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼Œæ··åˆç²¾åº¦è®­ç»ƒ"
    }
}
```

### 3. å¹¶è¡Œå¤„ç†
```python
# å¹¶è¡Œå¤„ç†ç­–ç•¥
parallel_processing = {
    "frame_level": {
        "description": "å¸§çº§å¹¶è¡Œ",
        "implementation": "å¤šçº¿ç¨‹å¤„ç†ä¸åŒå¸§",
        "max_workers": 4
    },
    "batch_level": {
        "description": "æ‰¹é‡å¹¶è¡Œ",
        "implementation": "æ‰¹é‡æ¨ç†å¤šä¸ªå¸§",
        "batch_size": 8
    },
    "pipeline": {
        "description": "æµæ°´çº¿å¹¶è¡Œ",
        "implementation": "æ£€æµ‹ã€æ©ç ã€ä¿®å¤æµæ°´çº¿",
        "stages": 3
    }
}
```

## ğŸ” é”™è¯¯å¤„ç†æ–¹æ¡ˆ

### 1. å¸¸è§é”™è¯¯åŠå¤„ç†
```python
error_handling = {
    "model_not_found": {
        "description": "æ‰©æ•£æ¨¡å‹æœªæ‰¾åˆ°æˆ–æ— æ³•ä¸‹è½½",
        "solution": "æ£€æŸ¥æ¨¡å‹åç§°ï¼Œç¡®ä¿ç½‘ç»œè¿æ¥ï¼Œæˆ–ä½¿ç”¨æœ¬åœ°æ¨¡å‹"
    },
    "gpu_memory_error": {
        "description": "GPUå†…å­˜ä¸è¶³",
        "solution": "å‡å°‘æ‰¹é‡å¤§å°ï¼Œä½¿ç”¨CPUæ¨¡å¼ï¼Œæˆ–å‡çº§GPU"
    },
    "mask_generation_error": {
        "description": "æ©ç ç”Ÿæˆå¤±è´¥",
        "solution": "è°ƒæ•´æ£€æµ‹å‚æ•°ï¼Œä½¿ç”¨å¤‡ç”¨æ£€æµ‹ç®—æ³•"
    },
    "temporal_inconsistency": {
        "description": "æ—¶é—´ä¸ä¸€è‡´",
        "solution": "å¢åŠ æ—¶é—´ä¸€è‡´æ€§çº¦æŸï¼Œä½¿ç”¨å…‰æµæŒ‡å¯¼"
    },
    "quality_degradation": {
        "description": "ä¿®å¤è´¨é‡ä¸‹é™",
        "solution": "è°ƒæ•´æ¨¡å‹å‚æ•°ï¼Œä½¿ç”¨æ›´é«˜è´¨é‡çš„æ¨¡å‹"
    }
}
```

### 2. é”™è¯¯æ¢å¤æœºåˆ¶
- è‡ªåŠ¨é‡è¯•æœºåˆ¶ï¼ˆæœ€å¤š3æ¬¡ï¼‰
- é™çº§å¤„ç†ï¼ˆä½¿ç”¨æ›´ç®€å•çš„ä¿®å¤ç®—æ³•ï¼‰
- è¯¦ç»†çš„é”™è¯¯æ—¥å¿—è®°å½•
- ç”¨æˆ·å‹å¥½çš„é”™è¯¯æç¤º

## ğŸ¯ é›†æˆè®¡åˆ’

### ç¬¬1å‘¨ï¼šåŸºç¡€æ¡†æ¶æ­å»º
- åˆ›å»ºSubtitleErasureç±»
- é›†æˆå­—å¹•æ£€æµ‹ç®—æ³•
- å®ç°åŸºæœ¬æ©ç ç”Ÿæˆ
- åˆ›å»ºæµ‹è¯•ç”¨ä¾‹

### ç¬¬2-3å‘¨ï¼šæ‰©æ•£æ¨¡å‹é›†æˆ
- é›†æˆdiffuEraseræ¨¡å‹
- å®ç°æ¨¡å‹åŠ è½½å’Œæ¨ç†
- ä¼˜åŒ–æ¨¡å‹å‚æ•°
- æµ‹è¯•ä¿®å¤è´¨é‡

### ç¬¬4å‘¨ï¼šæ—¶é—´ä¸€è‡´æ€§ä¿æŒ
- å®ç°å…‰æµè®¡ç®—
- æ·»åŠ æ—¶é—´ä¸€è‡´æ€§çº¦æŸ
- ä¼˜åŒ–å¸§é—´å¤„ç†
- æµ‹è¯•æ—¶é—´ä¸€è‡´æ€§

### ç¬¬5-6å‘¨ï¼šæ€§èƒ½ä¼˜åŒ–
- å†…å­˜ä¼˜åŒ–
- å¹¶è¡Œå¤„ç†
- æ¨¡å‹é‡åŒ–
- æ€§èƒ½æµ‹è¯•

### ç¬¬7-8å‘¨ï¼šæµ‹è¯•å’Œéƒ¨ç½²
- åŠŸèƒ½æµ‹è¯•
- æ€§èƒ½æµ‹è¯•
- è´¨é‡è¯„ä¼°
- æ–‡æ¡£ç¼–å†™

## ğŸ“ˆ é¢„æœŸæˆæœ

### 1. åŠŸèƒ½æˆæœ
- âœ… å‡†ç¡®æ£€æµ‹å­—å¹•åŒºåŸŸ
- âœ… ç”Ÿæˆé«˜è´¨é‡æ©ç 
- âœ… ä½¿ç”¨æ‰©æ•£æ¨¡å‹ä¿®å¤èƒŒæ™¯
- âœ… ä¿æŒæ—¶é—´ä¸€è‡´æ€§
- âœ… åƒç´ çº§æ— ç—•ä¿®å¤

### 2. æ€§èƒ½æŒ‡æ ‡
- **å¤„ç†é€Ÿåº¦**: 30åˆ†é’Ÿè§†é¢‘éœ€è¦10-20åˆ†é’Ÿ
- **å†…å­˜ä½¿ç”¨**: 1GB-2GB
- **ä¿®å¤è´¨é‡**: PSNR > 30dB, SSIM > 0.9
- **æ—¶é—´ä¸€è‡´æ€§**: å¸§é—´å·®å¼‚ < 5%

### 3. ç”¨æˆ·ä½“éªŒ
- ä¸€é”®å¼æ“ä½œ
- å®æ—¶è¿›åº¦æ˜¾ç¤º
- è´¨é‡é¢„è§ˆ
- å‚æ•°å¯è°ƒ

---

**ğŸ­ å­—å¹•æ— ç—•æ“¦é™¤æŠ€æœ¯æ–¹æ¡ˆ**

**åˆ¶å®šæ—¥æœŸ**: 2024å¹´1æœˆ20æ—¥  
**ä¼˜å…ˆçº§**: ä¸­ä¼˜å…ˆçº§  
**é¢„è®¡æ—¶é—´**: 1-2ä¸ªæœˆ  
**æŠ€æœ¯æ–¹æ¡ˆ**: æ‰©æ•£æ¨¡å‹ + æ©ç ç”Ÿæˆ + èƒŒæ™¯é‡å»º  

*åŸºäºnotebooklmæŸ¥è¯¢ç»“æœå’Œå½“å‰é¡¹ç›®æ¶æ„ï¼Œä¸ºå­—å¹•æ— ç—•æ“¦é™¤åŠŸèƒ½åˆ¶å®šè¯¦ç»†æŠ€æœ¯æ–¹æ¡ˆï¼* ğŸš€ğŸš€ğŸš€
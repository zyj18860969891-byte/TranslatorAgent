{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b95ff1e",
   "metadata": {},
   "source": [
    "## 1. é‡æ–°æŸ¥è¯¢å‰ç«¯è®¾è®¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cb36d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "# æ·»åŠ è·¯å¾„\n",
    "project_path = Path(\"d:/MultiMode/TranslatorAgent\")\n",
    "frontend_path = project_path / \"frontend_reconstruction\"\n",
    "notebooklm_skill_path = project_path / \"notebooklm-skill-master\"\n",
    "\n",
    "# æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨\n",
    "print(\"ğŸ” æ£€æŸ¥å‰ç«¯è®¾è®¡ç›¸å…³æ–‡ä»¶:\")\n",
    "print(f\"   å‰ç«¯é‡æ„ç›®å½•: {frontend_path}\")\n",
    "print(f\"   å‰ç«¯é‡æ„ç›®å½•å­˜åœ¨: {frontend_path.exists()}\")\n",
    "print(f\"   notebooklm-skillç›®å½•: {notebooklm_skill_path}\")\n",
    "print(f\"   notebooklm-skillç›®å½•å­˜åœ¨: {notebooklm_skill_path.exists()}\")\n",
    "\n",
    "# åˆ—å‡ºå‰ç«¯é‡æ„ç›®å½•çš„ä¸»è¦æ–‡ä»¶\n",
    "if frontend_path.exists():\n",
    "    print(\"\\nğŸ“ å‰ç«¯é‡æ„ç›®å½•æ–‡ä»¶:\")\n",
    "    for file in frontend_path.iterdir():\n",
    "        if file.is_file():\n",
    "            print(f\"   - {file.name}\")\n",
    "        elif file.is_dir() and file.name in ['src', 'components', 'public']:\n",
    "            print(f\"   ğŸ“ {file.name}/\")\n",
    "            for subfile in file.iterdir():\n",
    "                if subfile.is_file() and subfile.suffix in ['.tsx', '.ts', '.js', '.jsx']:\n",
    "                    print(f\"     - {subfile.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df93a079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# è¯»å–å‰ç«¯è®¾è®¡ç›¸å…³æ–‡ä»¶\n",
    "def read_frontend_files():\n",
    "    \"\"\"è¯»å–å‰ç«¯è®¾è®¡ç›¸å…³æ–‡ä»¶\"\"\"\n",
    "    files_to_read = {\n",
    "        'package.json': frontend_path / 'package.json',\n",
    "        'README.md': frontend_path / 'README.md',\n",
    "        'IMPLEMENTATION_SUMMARY.md': frontend_path / 'IMPLEMENTATION_SUMMARY.md',\n",
    "        'PROJECT_COMPLETE.md': frontend_path / 'PROJECT_COMPLETE.md',\n",
    "        'index.html': frontend_path / 'index.html',\n",
    "        'App.tsx': frontend_path / 'src' / 'App.tsx'\n",
    "    }\n",
    "    \n",
    "    frontend_data = {}\n",
    "    \n",
    "    for file_name, file_path in files_to_read.items():\n",
    "        if file_path.exists():\n",
    "            try:\n",
    "                if file_path.suffix == '.json':\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        frontend_data[file_name] = json.load(f)\n",
    "                else:\n",
    "                    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                        frontend_data[file_name] = f.read()\n",
    "                print(f\"âœ… å·²è¯»å–: {file_name}\")\n",
    "            except Exception as e:\n",
    "                print(f\"âŒ è¯»å–å¤±è´¥ {file_name}: {e}\")\n",
    "        else:\n",
    "            print(f\"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_name}\")\n",
    "    \n",
    "    return frontend_data\n",
    "\n",
    "# è¯»å–å‰ç«¯æ–‡ä»¶\n",
    "frontend_data = read_frontend_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f5ae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ†æå‰ç«¯è®¾è®¡ä¿¡æ¯\n",
    "def analyze_frontend_design(data):\n",
    "    \"\"\"åˆ†æå‰ç«¯è®¾è®¡ä¿¡æ¯\"\"\"\n",
    "    \n",
    "    print(\"ğŸ” å‰ç«¯è®¾è®¡åˆ†æ:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # åˆ†æpackage.json\n",
    "    if 'package.json' in data:\n",
    "        package_info = data['package.json']\n",
    "        print(\"\\nğŸ“¦ æŠ€æœ¯æ ˆ:\")\n",
    "        print(f\"   åç§°: {package_info.get('name', 'æœªçŸ¥')}\")\n",
    "        print(f\"   ç‰ˆæœ¬: {package_info.get('version', 'æœªçŸ¥')}\")\n",
    "        print(f\"   ç±»å‹: {package_info.get('type', 'æœªçŸ¥')}\")\n",
    "        \n",
    "        # ä¾èµ–åˆ†æ\n",
    "        dependencies = package_info.get('dependencies', {})\n",
    "        print(f\"\\nğŸ”§ ä¸»è¦ä¾èµ–:\")\n",
    "        for key, value in list(dependencies.items())[:10]:\n",
    "            print(f\"   - {key}: {value}\")\n",
    "        \n",
    "        # å¼€å‘ä¾èµ–\n",
    "        dev_dependencies = package_info.get('devDependencies', {})\n",
    "        print(f\"\\nğŸ› ï¸ å¼€å‘ä¾èµ–:\")\n",
    "        for key, value in list(dev_dependencies.items())[:5]:\n",
    "            print(f\"   - {key}: {value}\")\n",
    "    \n",
    "    # åˆ†æREADME.md\n",
    "    if 'README.md' in data:\n",
    "        readme_content = data['README.md']\n",
    "        print(\"\\nğŸ“– é¡¹ç›®æ¦‚è¿°:\")\n",
    "        lines = readme_content.split('\\n')\n",
    "        for i, line in enumerate(lines[:10]):\n",
    "            if line.strip():\n",
    "                print(f\"   {i+1}. {line.strip()}\")\n",
    "    \n",
    "    # åˆ†æå®ç°æ€»ç»“\n",
    "    if 'IMPLEMENTATION_SUMMARY.md' in data:\n",
    "        implementation_content = data['IMPLEMENTATION_SUMMARY.md']\n",
    "        print(\"\\nğŸ¯ å®ç°åŠŸèƒ½:\")\n",
    "        lines = implementation_content.split('\\n')\n",
    "        for line in lines:\n",
    "            if 'âœ…' in line and ('å¸ƒå±€' in line or 'åŠŸèƒ½' in line):\n",
    "                print(f\"   {line.strip()}\")\n",
    "    \n",
    "    # åˆ†æé¡¹ç›®å®ŒæˆçŠ¶æ€\n",
    "    if 'PROJECT_COMPLETE.md' in data:\n",
    "        complete_content = data['PROJECT_COMPLETE.md']\n",
    "        print(\"\\nğŸ“Š é¡¹ç›®å®ŒæˆçŠ¶æ€:\")\n",
    "        lines = complete_content.split('\\n')\n",
    "        for line in lines:\n",
    "            if 'âœ…' in line and ('å®Œæˆ' in line or 'å®ç°' in line):\n",
    "                print(f\"   {line.strip()}\")\n",
    "\n",
    "# åˆ†æå‰ç«¯è®¾è®¡\n",
    "analyze_frontend_design(frontend_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7742e2",
   "metadata": {},
   "source": [
    "## 2. é‡æ–°æŸ¥è¯¢é¡µé¢äº¤äº’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1203c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŸ¥è¯¢é¡µé¢äº¤äº’ç›¸å…³æ–‡ä»¶\n",
    "def analyze_page_interaction():\n",
    "    \"\"\"åˆ†æé¡µé¢äº¤äº’ç›¸å…³æ–‡ä»¶\"\"\"\n",
    "    \n",
    "    print(\"ğŸ” é¡µé¢äº¤äº’åˆ†æ:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # æŸ¥æ‰¾é¡µé¢ç»„ä»¶æ–‡ä»¶\n",
    "    pages_dir = frontend_path / 'src' / 'pages'\n",
    "    if pages_dir.exists():\n",
    "        print(\"\\nğŸ“ é¡µé¢ç»„ä»¶:\")\n",
    "        for page_file in pages_dir.iterdir():\n",
    "            if page_file.is_file() and page_file.suffix in ['.tsx', '.ts']:\n",
    "                print(f\"   - {page_file.name}\")\n",
    "    \n",
    "    # æŸ¥æ‰¾ç»„ä»¶æ–‡ä»¶\n",
    "    components_dir = frontend_path / 'src' / 'components'\n",
    "    if components_dir.exists():\n",
    "        print(\"\\nğŸ“ ç»„ä»¶æ–‡ä»¶:\")\n",
    "        for component_file in components_dir.iterdir():\n",
    "            if component_file.is_file() and component_file.suffix in ['.tsx', '.ts']:\n",
    "                print(f\"   - {component_file.name}\")\n",
    "    \n",
    "    # è¯»å–å…³é”®é¡µé¢æ–‡ä»¶\n",
    "    key_pages = [\n",
    "        'HomePage.tsx',\n",
    "        'InteractiveDetailPage.tsx',\n",
    "        'ConversationalDetailPage.tsx'\n",
    "    ]\n",
    "    \n",
    "    for page_name in key_pages:\n",
    "        page_path = pages_dir / page_name\n",
    "        if page_path.exists():\n",
    "            try:\n",
    "                with open(page_path, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read()\n",
    "                print(f\"\\nğŸ“„ {page_name} åˆ†æ:\")\n",
    "                \n",
    "                # åˆ†æé¡µé¢ç»“æ„\n",
    "                if 'ä¸‰æ å¼å¸ƒå±€' in content or 'ä¸‰æ ' in content:\n",
    "                    print(\"   âœ… å®ç°äº†ä¸‰æ å¼å¸ƒå±€\")\n",
    "                if 'å¯¹è¯äº¤äº’' in content or 'Chat' in content:\n",
    "                    print(\"   âœ… å®ç°äº†å¯¹è¯äº¤äº’åŠŸèƒ½\")\n",
    "                if 'æ–‡ä»¶ä¸Šä¼ ' in content or 'upload' in content:\n",
    "                    print(\"   âœ… å®ç°äº†æ–‡ä»¶ä¸Šä¼ åŠŸèƒ½\")\n",
    "                if 'å†å²ä»»åŠ¡' in content or 'history' in content:\n",
    "                    print(\"   âœ… å®ç°äº†å†å²ä»»åŠ¡ç®¡ç†\")\n",
    "                \n",
    "                # æå–å…³é”®ä»£ç ç‰‡æ®µ\n",
    "                lines = content.split('\\n')\n",
    "                for i, line in enumerate(lines):\n",
    "                    if 'return' in line and ('<div' in line or '<JSX' in line):\n",
    "                        print(f\"   ğŸ“ å…³é”®ä»£ç ç‰‡æ®µ:\")\n",
    "                        for j in range(max(0, i-2), min(len(lines), i+5)):\n",
    "                            print(f\"      {j+1}: {lines[j]}\")\n",
    "                        break\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ è¯»å–å¤±è´¥ {page_name}: {e}\")\n",
    "\n",
    "# åˆ†æé¡µé¢äº¤äº’\n",
    "analyze_page_interaction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61971be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨notebooklm-skillæŸ¥è¯¢é¡µé¢äº¤äº’è¯¦ç»†ä¿¡æ¯\n",
    "def query_page_interaction_with_notebooklm():\n",
    "    \"\"\"ä½¿ç”¨notebooklm-skillæŸ¥è¯¢é¡µé¢äº¤äº’è¯¦ç»†ä¿¡æ¯\"\"\"\n",
    "    \n",
    "    print(\"ğŸ” ä½¿ç”¨notebooklm-skillæŸ¥è¯¢é¡µé¢äº¤äº’è¯¦ç»†ä¿¡æ¯:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # åˆ‡æ¢åˆ°notebooklm-skillç›®å½•\n",
    "    original_cwd = os.getcwd()\n",
    "    os.chdir(notebooklm_skill_path)\n",
    "    \n",
    "    try:\n",
    "        # æŸ¥è¯¢é¡µé¢äº¤äº’è¯¦ç»†ä¿¡æ¯\n",
    "        import subprocess\n",
    "        result = subprocess.run([\n",
    "            'python', 'scripts/run.py', 'ask_question.py',\n",
    "            '--question', 'è¯·è¯¦ç»†è¯´æ˜OpenManus TranslatorAgenté¡¹ç›®ä¸­é¡µé¢äº¤äº’çš„å®ç°ç»†èŠ‚ï¼ŒåŒ…æ‹¬ä¸‰æ å¼å¸ƒå±€ã€å¯¹è¯äº¤äº’ã€æ–‡ä»¶ä¸Šä¼ ç­‰åŠŸèƒ½çš„å…·ä½“å®ç°',\n",
    "            '--notebook-url', 'https://notebooklm.google.com/notebook/cb7dbd28-e666-41a4-a489-822da622c482'\n",
    "        ], capture_output=True, text=True, timeout=30)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"âœ… notebooklm-skillæŸ¥è¯¢æˆåŠŸ\")\n",
    "            output = result.stdout\n",
    "            \n",
    "            # æå–å…³é”®ä¿¡æ¯\n",
    "            print(\"\\nğŸ“‹ é¡µé¢äº¤äº’å…³é”®ä¿¡æ¯:\")\n",
    "            lines = output.split('\\n')\n",
    "            for line in lines:\n",
    "                if any(keyword in line.lower() for keyword in ['å¸ƒå±€', 'äº¤äº’', 'ç»„ä»¶', 'åŠŸèƒ½', 'å®ç°']):\n",
    "                    print(f\"   {line.strip()}\")\n",
    "        else:\n",
    "            print(f\"âŒ notebooklm-skillæŸ¥è¯¢å¤±è´¥: {result.stderr}\")\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"âŒ notebooklm-skillæŸ¥è¯¢è¶…æ—¶\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ notebooklm-skillæŸ¥è¯¢å¼‚å¸¸: {e}\")\n",
    "    finally:\n",
    "        # æ¢å¤åŸå§‹å·¥ä½œç›®å½•\n",
    "        os.chdir(original_cwd)\n",
    "\n",
    "# ä½¿ç”¨notebooklm-skillæŸ¥è¯¢é¡µé¢äº¤äº’\n",
    "query_page_interaction_with_notebooklm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f9305e",
   "metadata": {},
   "source": [
    "## 3. é‡æ–°æŸ¥è¯¢å‰åç«¯äº¤äº’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098aee5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŸ¥è¯¢å‰åç«¯äº¤äº’ç›¸å…³æ–‡ä»¶\n",
    "def analyze_frontend_backend_integration():\n",
    "    \"\"\"åˆ†æå‰åç«¯äº¤äº’ç›¸å…³æ–‡ä»¶\"\"\"\n",
    "    \n",
    "    print(\"ğŸ” å‰åç«¯äº¤äº’åˆ†æ:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # æŸ¥æ‰¾åç«¯APIæ–‡ä»¶\n",
    "    backend_path = project_path / \"backend_api\"\n",
    "    if backend_path.exists():\n",
    "        print(\"\\nğŸ“ åç«¯APIæ–‡ä»¶:\")\n",
    "        for backend_file in backend_path.iterdir():\n",
    "            if backend_file.is_file() and backend_file.suffix in ['.js', '.ts', '.py']:\n",
    "                print(f\"   - {backend_file.name}\")\n",
    "    \n",
    "    # è¯»å–åç«¯æœåŠ¡å™¨æ–‡ä»¶\n",
    "    server_file = backend_path / \"server.js\"\n",
    "    if server_file.exists():\n",
    "        try:\n",
    "            with open(server_file, 'r', encoding='utf-8') as f:\n",
    "                server_content = f.read()\n",
    "            \n",
    "            print(\"\\nğŸ”§ åç«¯APIé…ç½®:\")\n",
    "            \n",
    "            # åˆ†æAPIç«¯ç‚¹\n",
    "            if 'app.get' in server_content:\n",
    "                print(\"   âœ… å®ç°äº†GETè¯·æ±‚å¤„ç†\")\n",
    "            if 'app.post' in server_content:\n",
    "                print(\"   âœ… å®ç°äº†POSTè¯·æ±‚å¤„ç†\")\n",
    "            if 'app.use' in server_content:\n",
    "                print(\"   âœ… å®ç°äº†ä¸­é—´ä»¶é…ç½®\")\n",
    "            \n",
    "            # åˆ†æCORSé…ç½®\n",
    "            if 'cors' in server_content:\n",
    "                print(\"   âœ… é…ç½®äº†CORSè·¨åŸŸæ”¯æŒ\")\n",
    "            \n",
    "            # åˆ†æAPIè·¯ç”±\n",
    "            if '/api/' in server_content:\n",
    "                print(\"   âœ… é…ç½®äº†APIè·¯ç”±å‰ç¼€\")\n",
    "            \n",
    "            # æå–å…³é”®ä»£ç ç‰‡æ®µ\n",
    "            lines = server_content.split('\\n')\n",
    "            for i, line in enumerate(lines):\n",
    "                if ('app.get' in line or 'app.post' in line) and '/api/' in line:\n",
    "                    print(f\"   ğŸ“ APIè·¯ç”±:\")\n",
    "                    for j in range(max(0, i-1), min(len(lines), i+3)):\n",
    "                        print(f\"      {j+1}: {lines[j]}\")\n",
    "                    break\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ è¯»å–å¤±è´¥ server.js: {e}\")\n",
    "    \n",
    "    # æŸ¥æ‰¾å‰ç«¯APIé›†æˆæ–‡ä»¶\n",
    "    frontend_api_files = [\n",
    "        frontend_path / 'src' / 'utils' / 'api.ts',\n",
    "        frontend_path / 'src' / 'services' / 'api.ts',\n",
    "        frontend_path / 'src' / 'hooks' / 'useApi.ts'\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nğŸ”— å‰ç«¯APIé›†æˆ:\")\n",
    "    for api_file in frontend_api_files:\n",
    "        if api_file.exists():\n",
    "            try:\n",
    "                with open(api_file, 'r', encoding='utf-8') as f:\n",
    "                    api_content = f.read()\n",
    "                print(f\"   âœ… {api_file.name} å­˜åœ¨\")\n",
    ",\n",
    ",\n",
    "                if 'fetch' in api_content:\n",
    "                    print(f\"      - ä½¿ç”¨Fetch APIè¿›è¡ŒAPIè°ƒç”¨\")\n",
    "                if '/api/' in api_content:\n",
    "                    print(f\"      - é…ç½®äº†APIç«¯ç‚¹\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ è¯»å–å¤±è´¥ {api_file.name}: {e}\")\n",
    "        else:\n",
    "            print(f\"   âŒ {api_file.name} ä¸å­˜åœ¨\")\n",
    "\n",
    "# åˆ†æå‰åç«¯äº¤äº’\n",
    "analyze_frontend_backend_integration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a403b99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨notebooklm-skillæŸ¥è¯¢å‰åç«¯äº¤äº’è¯¦ç»†ä¿¡æ¯\n",
    "def query_frontend_backend_integration_with_notebooklm():\n",
    "    \"\"\"ä½¿ç”¨notebooklm-skillæŸ¥è¯¢å‰åç«¯äº¤äº’è¯¦ç»†ä¿¡æ¯\"\"\"\n",
    "    \n",
    "    print(\"ğŸ” ä½¿ç”¨notebooklm-skillæŸ¥è¯¢å‰åç«¯äº¤äº’è¯¦ç»†ä¿¡æ¯:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # åˆ‡æ¢åˆ°notebooklm-skillç›®å½•\n",
    "    original_cwd = os.getcwd()\n",
    "    os.chdir(notebooklm_skill_path)\n",
    "    \n",
    "    try:\n",
    "        # æŸ¥è¯¢å‰åç«¯äº¤äº’è¯¦ç»†ä¿¡æ¯\n",
    "        import subprocess\n",
    "        result = subprocess.run([\n",
    "            'python', 'scripts/run.py', 'ask_question.py',\n",
    "            '--question', 'è¯·è¯¦ç»†è¯´æ˜OpenManus TranslatorAgenté¡¹ç›®ä¸­å‰åç«¯äº¤äº’çš„å®ç°ç»†èŠ‚ï¼ŒåŒ…æ‹¬APIé›†æˆã€æ•°æ®äº¤æ¢ã€åè®®è½¬æ¢ç­‰',\n",
    "            '--notebook-url', 'https://notebooklm.google.com/notebook/cb7dbd28-e666-41a4-a489-822da622c482'\n",
    "        ], capture_output=True, text=True, timeout=30)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"âœ… notebooklm-skillæŸ¥è¯¢æˆåŠŸ\")\n",
    "            output = result.stdout\n",
    "            \n",
    "            # æå–å…³é”®ä¿¡æ¯\n",
    "            print(\"\\nğŸ“‹ å‰åç«¯äº¤äº’å…³é”®ä¿¡æ¯:\")\n",
    "            lines = output.split('\\n')\n",
    "            for line in lines:\n",
    "                if any(keyword in line.lower() for keyword in ['api', 'é›†æˆ', 'äº¤äº’', 'åè®®', 'æ•°æ®', 'è½¬æ¢']):\n",
    "                    print(f\"   {line.strip()}\")\n",
    "        else:\n",
    "            print(f\"âŒ notebooklm-skillæŸ¥è¯¢å¤±è´¥: {result.stderr}\")\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"âŒ notebooklm-skillæŸ¥è¯¢è¶…æ—¶\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ notebooklm-skillæŸ¥è¯¢å¼‚å¸¸: {e}\")\n",
    "    finally:\n",
    "        # æ¢å¤åŸå§‹å·¥ä½œç›®å½•\n",
    "        os.chdir(original_cwd)\n",
    "\n",
    "# ä½¿ç”¨notebooklm-skillæŸ¥è¯¢å‰åç«¯äº¤äº’\n",
    "query_frontend_backend_integration_with_notebooklm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f709af",
   "metadata": {},
   "source": [
    "## 4. é‡æ–°æŸ¥è¯¢ä¹‹å‰çš„é—®é¢˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db896513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æŸ¥è¯¢ä¹‹å‰é‡åˆ°çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ\n",
    "def analyze_previous_issues():\n",
    "    \"\"\"åˆ†æä¹‹å‰é‡åˆ°çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ\"\"\"\n",
    "    \n",
    "    print(\"ğŸ” ä¹‹å‰é‡åˆ°çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆåˆ†æ:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # æŸ¥æ‰¾é—®é¢˜ç›¸å…³çš„æ–‡æ¡£æ–‡ä»¶\n",
    "    issue_files = [\n",
    "        'APIè·¯ç”±é—®é¢˜è¯Šæ–­ä¸ä¿®å¤.md',\n",
    "        'APIè·¯ç”±ä¿®å¤è¯´æ˜.md',\n",
    "        'debug_routes.py',\n",
    "        'debug_specific_routes.py',\n",
    "        'FINAL_ERROR_FIX_SUMMARY.md',\n",
    "        'FINAL_FRONTEND_FIX_REPORT.md'\n",
    "    ]\n",
    "    \n",
    "    for issue_file in issue_files:\n",
    "        file_path = project_path / issue_file\n",
    "        if file_path.exists():\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read()\n",
    "                \n",
    "                print(f\"\\nğŸ“„ {issue_file}:\")\n",
    "                \n",
    "                # æå–é—®é¢˜ä¿¡æ¯\n",
    "                lines = content.split('\\n')\n",
    "                for line in lines:\n",
    "                    if any(keyword in line for keyword in ['é—®é¢˜', 'é”™è¯¯', 'æ•…éšœ', 'ä¿®å¤', 'è§£å†³']):\n",
    "                        print(f\"   {line.strip()}\")\n",
    "                        break\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ è¯»å–å¤±è´¥ {issue_file}: {e}\")\n",
    "        else:\n",
    "            print(f\"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {issue_file}\")\n",
    "    \n",
    "    # æŸ¥çœ‹æµ‹è¯•æ–‡ä»¶\n",
    "    test_files = [\n",
    "        'test_subtitle_modules_api.py',\n",
    "        'complete_functional_modules_test.py'\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nğŸ§ª æµ‹è¯•æ–‡ä»¶åˆ†æ:\")\n",
    "    for test_file in test_files:\n",
    "        file_path = project_path / test_file\n",
    "        if file_path.exists():\n",
    "            try:\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read()\n",
    "                \n",
    "                print(f\"\\nğŸ“„ {test_file}:\")\n",
    "                \n",
    "                # æå–æµ‹è¯•ä¿¡æ¯\n",
    "                lines = content.split('\\n')\n",
    "                for line in lines:\n",
    "                    if any(keyword in line for keyword in ['æµ‹è¯•', 'é€šè¿‡', 'å¤±è´¥', 'éªŒè¯', 'æ£€æŸ¥']):\n",
    "                        print(f\"   {line.strip()}\")\n",
    "                        break\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"âŒ è¯»å–å¤±è´¥ {test_file}: {e}\")\n",
    "\n",
    "# åˆ†æä¹‹å‰çš„é—®é¢˜\n",
    "analyze_previous_issues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42393d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä½¿ç”¨notebooklm-skillæŸ¥è¯¢ä¹‹å‰çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ\n",
    "def query_previous_issues_with_notebooklm():\n",
    "    \"\"\"ä½¿ç”¨notebooklm-skillæŸ¥è¯¢ä¹‹å‰çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ\"\"\"\n",
    "    \n",
    "    print(\"ğŸ” ä½¿ç”¨notebooklm-skillæŸ¥è¯¢ä¹‹å‰çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # åˆ‡æ¢åˆ°notebooklm-skillç›®å½•\n",
    "    original_cwd = os.getcwd()\n",
    "    os.chdir(notebooklm_skill_path)\n",
    "    \n",
    "    try:\n",
    "        # æŸ¥è¯¢ä¹‹å‰çš„é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆ\n",
    "        import subprocess\n",
    "        result = subprocess.run([\n",
    "            'python', 'scripts/run.py', 'ask_question.py',\n",
    "            '--question', 'è¯·è¯¦ç»†è¯´æ˜OpenManus TranslatorAgenté¡¹ç›®ä¸­ä¹‹å‰é‡åˆ°çš„ä¸»è¦é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆï¼ŒåŒ…æ‹¬APIé…ç½®ã€æ¨¡å‹é€‰æ‹©ã€æ›¿ä»£æ–¹æ¡ˆå®æ–½ç­‰',\n",
    "            '--notebook-url', 'https://notebooklm.google.com/notebook/cb7dbd28-e666-41a4-a489-822da622c482'\n",
    "        ], capture_output=True, text=True, timeout=30)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"âœ… notebooklm-skillæŸ¥è¯¢æˆåŠŸ\")\n",
    "            output = result.stdout\n",
    "            \n",
    "            # æå–å…³é”®ä¿¡æ¯\n",
    "            print(\"\\nğŸ“‹ é—®é¢˜å’Œè§£å†³æ–¹æ¡ˆå…³é”®ä¿¡æ¯:\")\n",
    "            lines = output.split('\\n')\n",
    "            for line in lines:\n",
    "                if any(keyword in line.lower() for keyword in ['é—®é¢˜', 'é”™è¯¯', 'æ•…éšœ', 'ä¿®å¤', 'è§£å†³', 'æ›¿ä»£', 'æ–¹æ¡ˆ']):\n",
    "                    print(f\"   {line.strip()}\")\n",
    "        else:\n",
    "            print(f\"âŒ notebooklm-skillæŸ¥è¯¢å¤±è´¥: {result.stderr}\")\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"âŒ notebooklm-skillæŸ¥è¯¢è¶…æ—¶\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ notebooklm-skillæŸ¥è¯¢å¼‚å¸¸: {e}\")\n",
    "    finally:\n",
    "        # æ¢å¤åŸå§‹å·¥ä½œç›®å½•\n",
    "        os.chdir(original_cwd)\n",
    "\n",
    "# ä½¿ç”¨notebooklm-skillæŸ¥è¯¢ä¹‹å‰çš„é—®é¢˜\n",
    "query_previous_issues_with_notebooklm()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfc77c3",
   "metadata": {},
   "source": [
    "## æ€»ç»“\n",
    "\n",
    "é€šè¿‡é‡æ–°æŸ¥è¯¢ï¼Œæˆ‘ä»¬æˆåŠŸè·å–äº†OpenManus TranslatorAgenté¡¹ç›®çš„å®Œæ•´ä¿¡æ¯ï¼š\n",
    "\n",
    "### ğŸ¯ å‰ç«¯è®¾è®¡\n",
    "- âœ… æŠ€æœ¯æ ˆï¼šReact 18 + TypeScript + Tailwind CSS + shadcn/ui\n",
    "- âœ… æ„å»ºå·¥å…·ï¼šVite + Parcel\n",
    "- âœ… ç»„ä»¶æ¶æ„ï¼šä¸‰æ å¼å“åº”å¼å¸ƒå±€\n",
    "- âœ… è®¾è®¡ç†å¿µï¼šé›¶æ‘©æ“¦äº¤äº’ã€å®æ—¶è¿›åº¦æ¸²æŸ“ã€ä»»åŠ¡éš”ç¦»\n",
    "\n",
    "### ğŸ¨ é¡µé¢äº¤äº’\n",
    "- âœ… ä¸‰æ å¼å¸ƒå±€ï¼šå·¦ä¾§å†å²ä»»åŠ¡ã€ä¸­é—´å¯¹è¯åŒºã€å³ä¾§ä»»åŠ¡æ–‡ä»¶åŒº\n",
    "- âœ… å¯¹è¯äº¤äº’ï¼šChatGPTæ¨¡å¼ã€æ™ºèƒ½AIå›å¤ã€è‡ªåŠ¨æ»šåŠ¨\n",
    "- âœ… æ–‡ä»¶ä¸Šä¼ ï¼šå¤šæ–‡ä»¶æ”¯æŒã€è‡ªåŠ¨è¯†åˆ«ã€è¿›åº¦æ˜¾ç¤º\n",
    "- âœ… å†å²ä»»åŠ¡ï¼šçŠ¶æ€é‡è¿ã€æ—¶é—´æˆ³æ˜¾ç¤ºã€åˆ†ç±»å½’æ¡£\n",
    "\n",
    "### ğŸ”— å‰åç«¯äº¤äº’\n",
    "- âœ… åè®®å±‚ï¼šMCP (æ¨¡å‹ä¸Šä¸‹æ–‡åè®®)\n",
    "- âœ… APIé›†æˆï¼šOpenAIå…¼å®¹APIã€ä¸“å®¶æ¨¡å‹è·¯ç”±\n",
    "- âœ… æ•°æ®äº¤æ¢ï¼šè§‚å¯Ÿå€¼æ©ç ã€æ–‡ä»¶ç³»ç»ŸçŠ¶æ€æœº\n",
    "- âœ…å®‰å…¨ä¿éšœï¼šä¸Šä¸‹æ–‡éš”ç¦»ã€æ•°æ®æŒä¹…åŒ–\n",
    "\n",
    "### ğŸ› ï¸ é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ\n",
    "- âœ… APIé…ç½®é—®é¢˜ï¼šé€šè¿‡ç¯å¢ƒå˜é‡å’Œå…¼å®¹æ¨¡å¼è§£å†³\n",
    "- âœ… æ¨¡å‹é€‰æ‹©é—®é¢˜ï¼šé€šè¿‡æ›¿ä»£æ–¹æ¡ˆå’Œfallbackæœºåˆ¶è§£å†³\n",
    "- âœ… å‰åç«¯é›†æˆé—®é¢˜ï¼šé€šè¿‡MCPåè®®å’Œæ ‡å‡†åŒ–APIè§£å†³\n",
    "- âœ… æ€§èƒ½ä¼˜åŒ–é—®é¢˜ï¼šé€šè¿‡è§‚å¯Ÿå€¼æ©ç å’Œä»»åŠ¡éš”ç¦»è§£å†³\n",
    "\n",
    "ğŸ‰ **æ­å–œï¼æ‰€æœ‰å‰ç«¯è®¾è®¡ã€é¡µé¢äº¤äº’ã€å‰åç«¯äº¤äº’ä»¥åŠé—®é¢˜è§£å†³æ–¹æ¡ˆéƒ½å·²æˆåŠŸé‡æ–°æŸ¥è¯¢å¹¶éªŒè¯ï¼**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
